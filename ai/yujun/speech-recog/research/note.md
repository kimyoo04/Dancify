# 필기 노트 1

## ChatGPT
```
프론트엔드에서 마이크를 통해 입력을 받으려고 하는데, 마이크가 5초정도 켜려고 해.
근데 이 시간동안 입력이 들어올지 안들어올지 모르는데, 모든 입력을 다 백엔드로 보내는 것을 비효율적이라고 생각해.
```
```
마이크를 통한 입력을 처리하는 가장 효율적인 방법은 입력이 실시간으로 처리되도록 하는 것입니다. 이를 위해 웹소켓 같은 실시간 통신 기술을 사용할 수 있습니다. 하지만 입력이 실제로 들어오는 시간을 알 수 없으니, 이런 상황에서는 다음과 같은 전략을 고려해 볼 수 있습니다:

음성 활동 감지(Voice Activity Detection, VAD): 음성이 감지되는 시점에만 데이터를 백엔드로 전송하는 것입니다. VAD는 노이즈와 실제 음성을 구별하는 알고리즘으로, 음성 입력이 시작되었는지와 끝났는지를 파악하는 데 사용될 수 있습니다.

자동 음성 인식(Automatic Speech Recognition, ASR): 이 기술은 말한 내용을 텍스트로 변환합니다. 사용자가 말하는 동안 실시간으로 텍스트를 생성하여 불필요한 데이터 전송을 최소화할 수 있습니다.

로컬 버퍼링: 마이크 입력을 일정 시간 동안 로컬에 저장한 후, 저장된 데이터가 특정 크기에 도달하면 백엔드로 전송합니다. 이 방식은 네트워크 사용량을 줄이는 데 도움이 됩니다.

이와 같은 방법들을 사용하면 사용자의 마이크 입력을 효율적으로 처리하고 네트워크 사용량을 최소화할 수 있습니다. 이 방법 중에서 어떤 것이 가장 적합한지는 애플리케이션의 요구 사항과 사용자의 환경에 따라 달라집니다.
```

---
## 음성 인식 검색(JS) 🏫 [link](https://triplexblog.kr/167)
- Web Speech API 사용
- 마이크를 통해 음성을 듣고, 이를 콘솔에 찍는 코드
- vito.ai가 API를 호출하고 모델에서 반환을 받아오는 것보다 빠른 것 같은 느낌적 느낌
- 📚 [github](https://github.com/younhoso/younhoso/tree/main/blogExample/voice_search/)

---
## 음성 인식 검색을 JS에서 TS로 코드 변경
- Typescript에 대해 리서치
- `.ts` 컴파일 위해 nvm 설치 → node를 설치하고 Javascript 코드를 Typescript로 변환
- 동작 방식에 대해서 확인함
    - 연속적 음절 인식 여부, 언어, 연속/단일 결과 반환, 언어 보정 확인
    - 버튼을 누르면 바로 음성인식이 되고, 인식을 완료했을 때는 `isRecognizing`을 통해 상태 판단
- 콘솔에 찍힌 텍스트를 찬솔님이 만든 딕셔너리에 input으로 넣는 로직
- 일단 Speech Recognition에서 인식한 결과를 콘솔에 찍고, 그 문자열을 txt로 저장하는 것까진 구현
- 시스템 설정에서 IP 주소를 보고 로컬 호스트 대신해서 입력하면 모바일에서 확인 가능
    - 확인 결과, 웹에서는 음성 인식하면 자동으로 인식이 종료되었으나 모바일에서는 종료되지 않고 계속 인식되는 문제가 있었음